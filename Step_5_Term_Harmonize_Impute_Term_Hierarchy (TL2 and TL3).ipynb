{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Term Harmonize - STEP 5 : Impute Hierarchy (TL2 and TL3)\n",
    "#### Author: Ryan Urbanowicz (ryanurb@upenn.edu) \n",
    "#### Institution: University of Pennsylvania - Perleman School of Medicine\n",
    "#### Project: CMREF Data Harmonization \n",
    "#### Date: 7/18/19\n",
    "\n",
    "#### Project Overview:\n",
    "See the first notebook in this series ('Step_1_Term_Harmonize_Data_Preparation.ipynb') for an overview of this project, these notebooks, the target application, data availability, code dependencies, and our strategy for generalizing the code in these notebooks. \n",
    "\n",
    "#### Notebook Summary:\n",
    "This notebook loads the working mapping file (following completion of LLT mapping (which we assume has been completed fully). Next it will perform the first two levels of term hierarchy imputation.  In the current target application this involves imputing the PTs from LLTs, and then imputing the HLTs from the PTs. PT imputation is direct, since there are no alternative branches possible, so this task can be fully automated. However HLT imputation includes possible branching, therefore further manual, subjective annotation will be required after running this notebook. Whenever the data includes relevant term data, we will apply fuzzy matching to assist in the selection of the most appropriate of available HLT branches. When this relevant term data is not available we pick the first of the possible branches by default.  Branch 'quality' is tracked much like term mapping quality. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Load Python packages required in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load necessary packages.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# Jupyter Notebook Hack: This code ensures that the results of multiple commands within a given cell are all displayed, rather than just the last. \n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "#Import Progress bar\n",
    "from tqdm import tnrange, tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Load Working Map File and Relevent Ontology Files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create general variable names for any target application specific values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input filename for 'target dataset' (excel file loaded in this application)\n",
    "target_study_data = 'Combined_MEDHX_TERMS_20studies.xlsx' \n",
    "\n",
    "ont_DL1_data = 'LLT.xlsx' # Input filename for ontology file defining all DL1 terms and their codes. \n",
    "ont_DL1_name_col = 'llt_name' # column label for DL1 term name\n",
    "ont_DL1_code_col ='llt_code' # column label for DL1 term code\n",
    "ont_DL1_cur_col = 'llt_currency' # column label for term currency\n",
    "ont_DL2_data = 'PT.xlsx' # Input filename for ontology file defining all DL2 terms and their codes. \n",
    "ont_DL2_name_col = 'pt_name' # column label for DL2 term name\n",
    "ont_DL2_code_col = 'pt_code' # column label for DL2 term code\n",
    "ont_DL3_DL2_data = 'HLT_PT.xlsx' # Input filename for ontology file defining connections between DL2 and DL3 term codes. \n",
    "ont_DL3_data = 'HLT.xlsx' # Input filename for ontology file defining all DL3 terms and their codes.\n",
    "ont_DL3_name_col = 'hlt_name' # column label for DL3 term name\n",
    "ont_DL3_code_col = 'hlt_code' # column label for DL3 term code\n",
    "\n",
    "ont_DL4_DL3_data = 'HLGT_HLT.xlsx' # Input filename for ontology file defining connections between DL3 and DL4 term codes. \n",
    "ont_DL4_data = 'HLGT.xlsx' # Input filename for ontology file defining all DL4 terms and their codes.\n",
    "ont_DL5_DL4_data = 'SOC_HLGT.xlsx' # Input filename for ontology file defining connections between DL4 and DL5 term codes. \n",
    "ont_DL5_data = 'SOC.xlsx' # Input filename for ontology file defining all DL5 terms and their codes.\n",
    "\n",
    "DL1_FT1 = 'MHTERM' # focus term 1: This term is available over all studies. \n",
    "DL1_FT2 = 'LLT_NAME' # focus term 3: an alternative term available for a subset of studies. This one supposedly conforms to the MedDRA standard so we expect it to yield more exact matches. May offer a better match for the lowest level of the standardized terminology.\n",
    "DL1_FT3 = 'MHMODIFY' # focus term 2: an alternative term available for a subset of studies. May offer a better match for the lowest level of the standardized terminology.\n",
    "\n",
    "DL2 = 'PT_NAME' # Secondary level terms (i.e. more general than DL1 terms)\n",
    "DL3 = 'HLT_NAME' # Tertiary level terms (i.e. more general than DL2 terms)\n",
    "DL4 = 'HLGT_NAME' # Quarternary level terms (i.e. more general than DL3 terms)\n",
    "DL5 = 'SOC_NAME' # Quinary Level terms (i.e. more general than DL4 terms)\n",
    "\n",
    "TL1_qual_code_header = 'LLT_map_code' # column name for lowest term level mapping quality code (added to mapping file)\n",
    "TL1_name_header = 'T_LLT' # column name for the 'mapped' TL1 - term name (added to mapping file)\n",
    "TL1_code_header = 'T_LLT_CODE' # column name for the 'mapped' TL1 - term code (added to mapping file)\n",
    "TL2_name_header = 'T_PT'\n",
    "TL2_code_header = 'T_PT_CODE'\n",
    "TL3_name_header = 'T_HLT'\n",
    "TL3_code_header = 'T_HLT_CODE'\n",
    "TL4_name_header = 'T_HLGT'\n",
    "TL4_code_header = 'T_HLGT_CODE'\n",
    "TL5_name_header = 'T_SOC'\n",
    "TL5_code_header = 'T_SOC_CODE'\n",
    "\n",
    "FZ1_FT1 = 'FZMatch_1_'+DL1_FT1 # column name for best FT1 fuzzy match (temporarily added to mapping file)\n",
    "FZ2_FT1 = 'FZMatch_2_'+DL1_FT1 # column name for second best FT1 fuzzy match (temporarily added to mapping file)\n",
    "FZ3_FT1 = 'FZMatch_3_'+DL1_FT1 # column name for third best FT1 fuzzy match (temporarily added to mapping file)\n",
    "FZ4_FT1 = 'FZMatch_4_'+DL1_FT1 # column name for fourth best FT1 fuzzy match (temporarily added to mapping file)\n",
    "FZ5_FT1 = 'FZMatch_5_'+DL1_FT1 # column name for fifth best FT1 fuzzy match (temporarily added to mapping file)\n",
    "\n",
    "FZMC = 'FZMatch_Choice_ID_'+DL1_FT1 #column name for the column where manual annotator will enter the number (1-5) indicating the FT1 fuzzy matched term that offers the best match (if a good one is identified)\n",
    "FZCT = 'FZMatch_Copied_Term' #column name for the column where manual annotator can alternatively manually copy in the MedDRA LLT term that best matches the term information in this row (can come from FT2 or FT3 if term was not identified in FT1)\n",
    "\n",
    "FZ1_FT2 = 'FZMatch_1_'+DL1_FT2 # column name for best FT2 fuzzy match (temporarily added to mapping file)\n",
    "FZ2_FT2 = 'FZMatch_2_'+DL1_FT2 # column name for second best FT2 fuzzy match (temporarily added to mapping file)\n",
    "FZ3_FT2 = 'FZMatch_3_'+DL1_FT2 # column name for third best FT2 fuzzy match (temporarily added to mapping file)\n",
    "FZ4_FT2 = 'FZMatch_4_'+DL1_FT2 # column name for forth best FT2 fuzzy match (temporarily added to mapping file)\n",
    "FZ5_FT2 = 'FZMatch_5_'+DL1_FT2 # column name for fifth best FT2 fuzzy match (temporarily added to mapping file)\n",
    "\n",
    "FZ1_FT3 = 'FZMatch_1_'+DL1_FT3 # column name for best FT3 fuzzy match (temporarily added to mapping file)\n",
    "FZ2_FT3 = 'FZMatch_2_'+DL1_FT3 # column name for second best FT3 fuzzy match (temporarily added to mapping file)\n",
    "FZ3_FT3 = 'FZMatch_3_'+DL1_FT3 # column name for third best FT3 fuzzy match (temporarily added to mapping file)\n",
    "FZ4_FT3 = 'FZMatch_4_'+DL1_FT3 # column name for forth best FT3 fuzzy match (temporarily added to mapping file)\n",
    "FZ5_FT3 = 'FZMatch_5_'+DL1_FT3 # column name for fifth best FT3 fuzzy match (temporarily added to mapping file)\n",
    "\n",
    "TL3_B = 'HLT_branches'\n",
    "TL3_BQ = 'HLT_branch_quality'\n",
    "TL3_FZT = 'HLT_Fuzzy_Terms'\n",
    "TL3_FZS = 'HLT_Fuzzy_Scores'\n",
    "\n",
    "TL4_B = 'HLGT_branches'\n",
    "TL4_BQ = 'HLGT_branch_quality'\n",
    "TL4_FZT = 'HLGT_Fuzzy_Terms'\n",
    "TL4_FZS = 'HLGT_Fuzzy_Scores'\n",
    "\n",
    "TL5_B = 'SOC_branches'\n",
    "TL5_BQ = 'SOC_branch_quality'\n",
    "TL5_FZT = 'SOC_Fuzzy_Terms'\n",
    "TL5_FZS = 'SOC_Fuzzy_Scores'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load mapping file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28720, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load target (tab-delimited) file into a pandas data frame\n",
    "target_map_file = 'MH_harmonization_map_9_Final.csv' #Input filename (excel file loaded in this application)\n",
    "td = pd.read_csv(target_map_file, na_values=' ') #Data loaded so that blank excell cells are 'NA'\n",
    "td.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Lowest Level Terminology Standard File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78808, 11)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(69531, 11)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl1 = pd.read_excel(ont_DL1_data, sep='\\t',na_values=' ')\n",
    "tl1.shape\n",
    "\n",
    "#Filter out any non-current low level terms (LLTs) \n",
    "tl1 = tl1.loc[tl1[ont_DL1_cur_col] == 'Y'] #column name is application specific.\n",
    "tl1.shape\n",
    "#Readjusts the row index values so there are no gaps in the sequence from the row removal (important for indexing later) \n",
    "tl1 = tl1.reset_index(drop=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load 2nd Level Terminology Standard File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23088, 11)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl2 = pd.read_excel(ont_DL2_data, sep='\\t',na_values=' ')\n",
    "tl2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load 3rd Level Terminology Standard File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1737, 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl3 = pd.read_excel(ont_DL3_data, sep='\\t',na_values=' ')\n",
    "tl3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load 2nd to 3rd Level Terminology Connection File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33402, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl3_tl2 = pd.read_excel(ont_DL3_DL2_data, sep='\\t',na_values=' ')\n",
    "tl3_tl2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Insert New Columns for Hierarchy Imputation\n",
    "Insert column into the mapping file needed for the first two levels of the hierarchy imputation (i.e. PT and HLT). For level 3 (i.e. HLT) we will also add columns to handle the branch possibilities, the quality of our branch selection, and results from any fuzzy branch matching. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*To adapt this code to other tasks, users may need to specify different column indexes below. We place these new columns after the original data columns.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "td.insert(loc=28,column=TL2_name_header,value='NA') \n",
    "td.insert(loc=29,column=TL2_code_header,value='NA') \n",
    "td.insert(loc=30,column=TL3_name_header,value='NA') \n",
    "td.insert(loc=31,column=TL3_code_header,value='NA') \n",
    "\n",
    "td.insert(loc=32,column=TL3_B,value='NA') \n",
    "td.insert(loc=33,column=TL3_BQ,value='NA') \n",
    "td.insert(loc=34,column=TL3_FZT,value='NA') \n",
    "td.insert(loc=35,column=TL3_FZS,value='NA') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Delete unnecessary columns\n",
    "Remove the fuzzy match result columns from the last notebook run.  These are not needed moving forward in the map file. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28720, 36)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(28720, 21)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td.shape\n",
    "#Drop FT1 fuzzy matching terms\n",
    "td = td.drop([FZ1_FT1,FZ2_FT1,FZ3_FT1,FZ4_FT1,FZ5_FT1], axis=1)\n",
    "\n",
    "#Drop FT2 fuzzy matching terms\n",
    "td = td.drop([FZ1_FT2,FZ2_FT2,FZ3_FT2,FZ4_FT2,FZ5_FT2], axis=1)\n",
    "\n",
    "#Drop FT3 fuzzy matching terms\n",
    "td = td.drop([FZ1_FT3,FZ2_FT3,FZ3_FT3,FZ4_FT3,FZ5_FT3], axis=1)\n",
    "td.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a method that takes a pandas column and turns it into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listify(inList):\n",
    "    nameList = []\n",
    "    scoreList = []\n",
    "    for each in inList:\n",
    "        nameList.append(each[0])\n",
    "        scoreList.append(each[1])\n",
    "    return nameList, scoreList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Impute TL2 from TL1 (Direct mapping)\n",
    "In this application we impute PTs (i.e. TL2) from previously mapped LLTs (TL1). Terms are directly linked, so the mapping is deterministic (i.e. no alternative branches exist).  This step is fully automated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb1b80df0e6a4feb940eef0a2da44216",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='1st loop', max=28720, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "data_count = 0\n",
    "for each in tqdm_notebook(td[TL1_code_header], desc='1st loop'): #for each row \n",
    "    if not pd.isna(each): #Check for missing value\n",
    "\n",
    "        #Idenfity the TL1 code in the MedDRA LLT file\n",
    "        tempList = tl1[ont_DL1_code_col].tolist() # the column name reference is specific to the loaded MedDRA file\n",
    "        tempIndex = tempList.index(each) \n",
    "\n",
    "        #Put the corresponding TL2 code into the key\n",
    "        TL2_code = tl1[ont_DL2_code_col][tempIndex] # the column name reference is specific to the loaded MedDRA file\n",
    "        td[TL2_code_header][data_count] = TL2_code\n",
    "\n",
    "        #Identify the TL2 name from the MedDRA PT file\n",
    "        tempList = tl2[ont_DL2_code_col].tolist() # the column name reference is specific to the loaded MedDRA file\n",
    "        tempIndex = tempList.index(TL2_code) \n",
    "\n",
    "        #Put the corresponding TL2 name into the key\n",
    "        TL2_name = tl2[ont_DL2_name_col][tempIndex] # the column name reference is specific to the loaded MedDRA file\n",
    "        td[TL2_name_header][data_count] = TL2_name\n",
    "    \n",
    "    data_count +=1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save file in progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td.to_csv(\"MH_harmonization_map_10_TL2.csv\", header=True, index=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Impute TL3 from TL2 (Branches Possible)\n",
    "In this application we impute HLTs (i.e. TL3) from previously imputed PTs (TL2). \n",
    "\n",
    "Before completing this task we lay out a coding scheme to describe the quality/confidence of any branch selection for this entire imputation proceedure. These codes for TL3 will be entered into the column with the 'TL3_BQ' label. We have developed a custom coding scheme to suit the needs of our target application:\n",
    "\n",
    "* 0 = No branching: Only one possible term available for imputation - best quality implied. \n",
    "* 1 = Branching: Branch selected based on an exact match with DL3 available term. \n",
    "* 2 = Branching: DL3 term available, fuzzy matching applied, top scoring fuzzy match chosen/confirmed. \n",
    "* 3 = Branching: DL3 term available, fuzzy matching applied, non-top scoring fuzzy match chosen/confirmed.\n",
    "* 4 = Branching: no DL3 term available - No fuzzy matching available. Picked first branch by default. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28720, 21)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84d9d3a7afb54b939f41c3f33305bead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='1st loop', max=28720), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directly Imputed: 18597\n",
      "With Branches: 10093\n"
     ]
    }
   ],
   "source": [
    "data = 'MH_harmonization_map_10_TL2.csv'\n",
    "td = pd.read_csv(data, na_values=' ')\n",
    "td.shape\n",
    "\n",
    "data_count = 0\n",
    "total_branched = 0\n",
    "total_direct = 0\n",
    "\n",
    "for each in tqdm_notebook(td[TL2_code_header], desc='1st loop'): #for each row\n",
    "    if not pd.isna(each): #Check for missing value\n",
    "        \n",
    "        #Idenfity the TL2 code in the MedDRA HLT_PT file\n",
    "        tempList = tl3_tl2[ont_DL2_code_col].tolist() # the column name reference is specific to the loaded MedDRA file\n",
    "        indexList = [i for i,val in enumerate(tempList) if val==each]\n",
    "\n",
    "        #Put all connected TL3 codes in TL3_B separated by an underscore\n",
    "        TL3_list = []\n",
    "        TL3_str = ''\n",
    "        for i in indexList:\n",
    "            TL3_list.append(tl3_tl2[ont_DL3_code_col][i]) # the column name reference is specific to the loaded MedDRA file\n",
    "            TL3_str += str(tl3_tl2[ont_DL3_code_col][i])+'_' # the column name reference is specific to the loaded MedDRA file\n",
    "\n",
    "        #Branch Reporting\n",
    "        if len(TL3_list) > 1: # is there more than one branch \n",
    "            total_branched += 1\n",
    "            td[TL3_B][data_count] = TL3_str\n",
    "\n",
    "        else: #only one branch found\n",
    "            total_direct += 1\n",
    "            #Identify term for single code\n",
    "            tempList = tl3[ont_DL3_code_col].tolist() # the column name reference is specific to the loaded MedDRA file\n",
    "\n",
    "            tempIndex = tempList.index(TL3_list[0]) #find index/location of code in tl3 set of terms\n",
    "            term = tl3[ont_DL3_name_col][tempIndex] # the column name reference is specific to the loaded MedDRA file\n",
    "\n",
    "            td[TL3_name_header][data_count] = term\n",
    "            td[TL3_code_header][data_count] = TL3_list[0]\n",
    "            td[TL3_BQ][data_count] = 0 # Top Branch Quality\n",
    "\n",
    "    data_count +=1 \n",
    "\n",
    "print(\"Directly Imputed: \" +str(total_direct))\n",
    "print(\"With Branches: \" +str(total_branched))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save file in progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "td.to_csv(\"MH_harmonization_map_11_TL3.csv\", header=True, index=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exact Matching of TL3 Branches\n",
    "This process will focus on TL3's with branches, as well as available DL3 terms to allow for exact matching. For any row without DL3 data, but multiple branches are available, we will pick the first branch by default and enter at TL3_BQ of 4 (lowest quality branch resolution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f58c8ad737d4872a05c5b856b9ec6cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='1st loop', max=28720), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Branches Resolved with Exact Match: 5013\n",
      "Branches with Data but No Exact Match: 658\n",
      "Branches with no Data: 4422\n"
     ]
    }
   ],
   "source": [
    "data_count = 0\n",
    "total_exact_matched = 0\n",
    "total_data_no_match = 0\n",
    "total_no_data = 0\n",
    "\n",
    "for each in tqdm_notebook(td[TL3_B], desc='1st loop'): #for each row\n",
    "    if not pd.isna(td[TL1_name_header][data_count]): #Check for missing value\n",
    "        \n",
    "        if td[TL3_BQ][data_count] != 0: # Focus on terms with multiple branches\n",
    "\n",
    "            #Create list of branch codes\n",
    "            codeList = each.strip('_').split('_')\n",
    "            #Get MedDRA terms for each code in branch list - put in a list of terms\n",
    "            textList = [] #text for corresponding branch terms\n",
    "            tempList = tl3[ont_DL3_code_col].tolist() # the column name reference is specific to the loaded MedDRA file\n",
    "\n",
    "            for code in codeList:\n",
    "                #Idenfity the TL3 code in the MedDRA HLT file\n",
    "                tempIndex = tempList.index(int(code))\n",
    "\n",
    "                #Put the corresponding TL3 term into the list\n",
    "                term = tl3[ont_DL3_name_col][tempIndex] # the column name reference is specific to the loaded MedDRA file\n",
    "                textList.append(str(term))\n",
    "\n",
    "            #Exact Matching\n",
    "            if not pd.isna(td[DL3][data_count]): #See if row has original DL3 data available.\n",
    "                #Check for branch exact match\n",
    "                term_count = 0\n",
    "                matched = False\n",
    "                for term in textList: #each branch term\n",
    "                    if str(term).casefold() == str(td[DL3][data_count]).casefold(): \n",
    "                        td[TL3_name_header][data_count] = term # Map matching term\n",
    "                        td[TL3_code_header][data_count] = codeList[term_count] # Map matching term code, the column name reference is specific to the loaded MedDRA LLT file\n",
    "                        td[TL3_BQ][data_count] = 1 # Exact Match Branch Quality\n",
    "                        total_exact_matched += 1\n",
    "                        matched = True\n",
    "                    term_count +=1\n",
    "                if not matched:\n",
    "                    total_data_no_match += 1\n",
    "\n",
    "            else: # no DL3 data\n",
    "                #Pick first branch by default.\n",
    "                td[TL3_name_header][data_count] = textList[0] # Map matching term\n",
    "                td[TL3_code_header][data_count] = codeList[0] # Map matching term code, the column name reference is specific to the loaded MedDRA LLT file\n",
    "                td[TL3_BQ][data_count] = 4 # First branch picked by default - lowest quality branch resolution code. \n",
    "                total_no_data += 1\n",
    "        \n",
    "    data_count +=1 \n",
    "\n",
    "print(\"Branches Resolved with Exact Match: \" +str(total_exact_matched))\n",
    "print(\"Branches with Data but No Exact Match: \" +str(total_data_no_match))  \n",
    "print(\"Branches with no Data: \" +str(total_no_data))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save file in progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "td.to_csv(\"MH_harmonization_map_12_TL3.csv\", header=True, index=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fuzzy Matching of TL3 Branches\n",
    "This process will focus on TL3's with branches, unresolved by exact matching, but have DL3 terms to allow for fuzzy matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28720, 21)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b463f6f6d6e439097e220cce40fc2a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='1st loop', max=28720), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Branches with Applied Fuzzy Matching: 658\n",
      "Branches with no Data: 28032\n"
     ]
    }
   ],
   "source": [
    "data = 'MH_harmonization_map_12_TL3.csv'\n",
    "td = pd.read_csv(data, na_values=' ')\n",
    "td.shape\n",
    "\n",
    "data_count = 0\n",
    "total_fuzzy_matched = 0\n",
    "total_no_data = 0\n",
    "\n",
    "for each in tqdm_notebook(td[TL3_B], desc='1st loop'): #for each row\n",
    "    if not pd.isna(td[TL1_name_header][data_count]): #Check for missing value\n",
    "        \n",
    "        if pd.isna(td[TL3_BQ][data_count]): #haven't previously assigned branch quality a code (i.e. of 0, 1, or 4) (i.e. multiple branches, no exact match, and DL3 available)\n",
    "\n",
    "            #Create list of branch codes\n",
    "            codeList = each.strip('_').split('_')\n",
    "            #Get MedDRA terms for each code in branch list - put in a list of terms\n",
    "            textList = [] #text for corresponding branch terms\n",
    "            tempList = tl3[ont_DL3_code_col].tolist() # the column name reference is specific to the loaded MedDRA file\n",
    "\n",
    "            for code in codeList:\n",
    "                #Idenfity the TL3 code in the MedDRA HLT file\n",
    "                tempIndex = tempList.index(int(code))\n",
    "\n",
    "                #Put the corresponding TL3 term into the list\n",
    "                term = tl3[ont_DL3_name_col][tempIndex] # the column name reference is specific to the loaded MedDRA file\n",
    "                textList.append(str(term))\n",
    "\n",
    "            #Perform fuzzy matching between row's HLT and term list\n",
    "            bestFound = process.extract(td[DL3][data_count],textList)\n",
    "            nameList,scoreList = listify(bestFound)\n",
    "\n",
    "            # Add results of fuzzy matching\n",
    "            td[TL3_FZT][data_count] = str(nameList)\n",
    "            td[TL3_FZS][data_count] = str(scoreList)\n",
    "\n",
    "            total_fuzzy_matched += 1\n",
    "        else:\n",
    "            total_no_data += 1\n",
    "            \n",
    "    data_count += 1\n",
    "    \n",
    "print(\"Branches with Applied Fuzzy Matching: \" +str(total_fuzzy_matched))\n",
    "print(\"Branches with no Data: \" +str(total_no_data))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Save working map file\n",
    "Before moving on to the next step of the harmonization pipeline we will save our mapping file 'in progress'. Since a row index was previously added, we will set index to 'False' below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "td.to_csv(\"MH_harmonization_map_13_TL3.csv\", header=True, index=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual annotation of fuzzy matched branch ranking\n",
    "At this point we manually created a modiefied version of (\"MH_harmonization_map_13_TL3.csv\") called ('MH_harmonization_map_13_TL3_Fuzzy.csv') where we remove any row with a TL3 branch quality code of 0 or 1 (i.e. direct or exact branch matches) to make it easier for the manual annotator to focus on the rows that need to be checked. Next the manual annotation is completed where an expert double checks the fuzzy matches and confirms the best branch adding the name of the branch into the term column (i.e. TL3_name_header).  This file is named ('MH_harmonization_map_13_TL3_Fuzzy_NAN.csv'). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrate the manually annotated fuzzy branch matching file with the original direct/exact branch matching file\n",
    "- load the original fuzzy branch matching file and remove rows with a code > 1.  This preserves the direct and exact branch matches. \n",
    "- load the manually annotated file and integrated with the file above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28720, 21)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(28062, 21)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'MH_harmonization_map_13_TL3.csv'\n",
    "td = pd.read_csv(data, na_values=' ')\n",
    "td.shape\n",
    "\n",
    "#Remove all rows from entire dataset with a code of 2, 3 or 4 (these will be replaced by the rows from the second round annotation dataset)\n",
    "td2 = td[td[TL3_FZT].isnull()]\n",
    "td2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(658, 21)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(28720, 21)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_fuz = 'MH_harmonization_map_13_TL3_Fuzzy_NAN.csv'\n",
    "tf = pd.read_csv(data_fuz, na_values=' ')\n",
    "tf.shape\n",
    "\n",
    "#combine the two, non-overlapping, manually annotated datasets\n",
    "frames = [td2, tf]\n",
    "\n",
    "td3 = pd.concat(frames)\n",
    "td3.shape\n",
    "\n",
    "td3.to_csv(\"MH_harmonization_map_14_TL3.csv\", header=True, index=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify and save term codes for all TL3 terms\n",
    "At this points we should have identified a term (in the column TL3_name_header) for all rows in the dataset where we had previously succeeded in mapping TL1 and TL2. Next we want to add the corresponding codes for each of these terms. This is automated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28720, 21)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fd36a6fd97e492e94614133b93d4954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='1st loop', max=28720), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "data = 'MH_harmonization_map_14_TL3.csv'\n",
    "td = pd.read_csv(data, na_values=' ')\n",
    "td.shape\n",
    "\n",
    "count = 0\n",
    "for each in tqdm_notebook(td[TL3_code_header], desc='1st loop'): #for each row\n",
    "    if not pd.isna(td[TL1_name_header][count]): #Check for missing value\n",
    "        \n",
    "        if pd.isna(each): \n",
    "            #Get MedDRA terms for each code in branch list - put in a list of terms\n",
    "            textList = [] #text for corresponding branch terms\n",
    "            tempList = tl3[ont_DL3_name_col].tolist() # the column name reference is specific to the loaded MedDRA file\n",
    "\n",
    "            #Identify the TL3 term in teh MedDRA HLT file\n",
    "            tempIndex = tempList.index(td[TL3_name_header][count])\n",
    "\n",
    "            #Put the corresponding TL3 code into the list\n",
    "            code = tl3[ont_DL3_code_col][tempIndex] # the column name reference is specific to the loaded MedDRA file\n",
    "            td[TL3_code_header][count] = int(code)\n",
    "            \n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Save working map file\n",
    "Before moving on to the next step of the harmonization pipeline we will save our mapping file 'in progress'. Since a row index was previously added, we will set index to 'False' below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "td.to_csv(\"MH_harmonization_map_15_TL3.csv\", header=True, index=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook conclusions\n",
    "In this notebook we have directly mapped all TL2 names and codes from all TL1 name/codes that had been previously mapped.  Next we mapped all TL3 names and codes, this time resolving any possible term branches using available term information in the dataset.  This was completed with exact and fuzzy matching similar to the first phase of TL1 mapping. \n",
    "\n",
    "In the next notebook we replicate the same process we just completed for TL3, but for TL4. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
